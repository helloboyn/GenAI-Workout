[Whitepaper Companion Podcast](https://youtube.com/playlist?list=PLqFaTIg4myu_yKJpvF8WE2JfaG5kGuvoE&si=_GDz2GWD57pS2cOg)

[Gen AI Intensive Course with Google Live](https://youtube.com/playlist?list=PLqFaTIg4myu-lbBTrUpoQQIzZZxvrOaP5&si=iyUSv3USuEF-ysfc)
# Unit 1: Foundational Large Language Models & Text Generation:

- 💻 

## 1. Complete the Intro Unit – "Foundational Large Language Models & Text Generation"
- 🎧 Listen to the [summary podcast episode](https://www.youtube.com/playlist?list=PLqFaTIg4myu_yKJpvF8WE2JfaG5kGuvoE) for all the unit. 
- 📖 Read the "[Foundational Large Language Models & Text Generation"](https://github.com/helloboyn/GenAI-Workout/blob/main/GenAI-Kaggle/Foundational%20Large%20Language%20Models%20%26%20Text%20Generation.pdf)

## 2. Complete Unit 1 – "Prompt Engineering"
- 🎧 Listen to the [summary podcast episode](https://www.youtube.com/watch?v=CFtX0ZyLSAY) for this unit.
- 📖 Read the "[Prompt Engineering](https://github.com/helloboyn/GenAI-Workout/blob/main/GenAI-Kaggle/Prompt%20Engineering.pdf)" and [Evaluating Large Language Models](https://github.com/helloboyn/GenAI-Workout/blob/main/GenAI-Kaggle/Evaluating%20LLM%20Principles%20Approaches%20and%20Applications.pdf)
- 🏗️ Complete these codelabs on Kaggle:
  - [Prompting fundamentals](https://github.com/helloboyn/GenAI-Workout/blob/main/GenAI-Kaggle/prompting-fundamentals.ipynb)
  - [Evaluation and structured data](https://github.com/helloboyn/GenAI-Workout/blob/main/GenAI-Kaggle/evaluation-and-structured-output.ipynb)

- The evolution of LLMs, from transformers to fine-tuning and inference acceleration.
- The art of prompt engineering for optimal LLM interaction.
- Evaluating LLMs effectively.


# Unit 2: Embeddings and Vector Stores/ Databases:


## 1. Complete the Intro Unit – *Foundational Large Language Models & Text Generation*:
- 📄 To complement the podcast, read the [“Foundational Large Language Models & Text Generation”](https://example.com).

## 2. Complete Unit 1 – *Prompt Engineering*:

- 🎧 Listen to the [summary podcast episode](https://example.com) for this unit.
- 📄 To complement the podcast, read the [“Prompt Engineering” whitepaper](https://example.com).
- 💻 Complete these codelabs on Kaggle:
  - [Prompting fundamentals](https://www.kaggle.com)
  - [Evaluation and structured data](https://www.kaggle.com)
- 🔐 Make sure you [phone verify](https://www.kaggle.com/account/verify) your Kaggle account before starting, it's necessary for the codelabs.
- 💬 Want to have an [interactive conversation](https://notebooklm.google.com)? Try adding the whitepapers to NotebookLM.

---

## 💡 What You’ll Learn

Today you’ll explore the evolution of LLMs, from transformers to techniques like fine-tuning and inference acceleration. You’ll also get trained in the art of prompt engineering for optimal LLM interaction and evaluating LLMs.

The first codelab will walk you through getting started with the Gemini 2.0 API and cover several prompt techniques including how different parameters impact the prompts. In the second codelab, you will also learn how to evaluate the response of LLMs using autoraters and structured output.
